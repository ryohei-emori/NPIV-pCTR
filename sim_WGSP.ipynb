{"cells":[{"cell_type":"markdown","metadata":{"id":"wcpZDp3Safyj"},"source":["### Step 1 & 2: Initializing and generating historical data"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":412,"status":"ok","timestamp":1718109160429,"user":{"displayName":"R E","userId":"10479407368002365455"},"user_tz":-540},"id":"Vv5WHGixk5zB"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from scipy.special import logit, expit\n","from scipy.stats import bernoulli, multivariate_normal\n","from sklearn.linear_model import LogisticRegression\n","\n","class AuctionData:\n","    def __init__(self):\n","        self.alpha = None\n","        self.beta = None\n","        self.gamma = None\n","        self.pCTR_biased = None\n","\n","    def generate_parameters(self, num_features):\n","        self.alpha = np.random.normal(0.1, 1, num_features)\n","        self.beta = np.random.normal(0.1, 1, num_features)\n","        self.gamma = np.random.normal(0.1, 1, num_features)\n","        #A = np.random.normal(0, 1, (num_features + 1, num_features + 1))\n","        #self.Sigma = np.dot(A, A.T)\n","\n","    def sample_reparameterized_beta(self, mu, phi, size):\n","        mu = np.clip(mu, 0.01, 0.99)\n","        alpha = mu * phi\n","        beta_param = (1 - mu) * phi\n","        return np.random.beta(alpha, beta_param, size=size)\n","\n","    def initialize_training_data(self, num_records_initial, num_features):\n","        X_k = []\n","        eta_k = []\n","        y_k = []\n","        D_k = []\n","        \n","        while len(D_k) < 5000:\n","            X_binary = np.random.binomial(1, 0.5, (num_records_initial, 10))\n","            X_uniform_5 = np.random.uniform(-5, 5, (num_records_initial, 10))\n","            X_uniform_2 = np.random.uniform(-2, 2, (num_records_initial, 5))\n","            X_tmp = np.hstack((X_binary, X_uniform_5, X_uniform_2))\n","            eta_tmp = np.random.uniform(-5, 5, num_records_initial)\n","            \n","            D_tmp_prob = expit(np.dot(X_tmp, self.gamma) + eta_tmp)\n","            D_tmp = bernoulli.rvs(D_tmp_prob)\n","            \n","            X_tmp = X_tmp[D_tmp == 1]\n","            eta_tmp = eta_tmp[D_tmp == 1]\n","            p_tmp = expit(np.dot(X_tmp, self.beta) + eta_tmp)\n","            y_tmp = bernoulli.rvs(p_tmp)\n","            D_tmp = D_tmp[D_tmp == 1]\n","            \n","            X_k.extend(X_tmp)\n","            eta_k.extend(eta_tmp)\n","            y_k.extend(y_tmp)\n","            D_k.extend(D_tmp)\n","\n","        return np.array(X_k)[:5000], np.array(eta_k)[:5000], np.array(y_k)[:5000], np.array(D_k)[:5000]\n","\n","    def train_logistic_regression(self, X_k, y_k):\n","        self.pCTR_biased = LogisticRegression()\n","        self.pCTR_biased.fit(X_k, y_k)\n","\n","    def generate_historical_auction_data(self, num_auctions, num_auctioneers_per_auction, num_features):\n","        historical_data = []\n","        for _ in range(num_auctions):\n","            X_binary = np.random.binomial(1, 0.5, (num_auctioneers_per_auction, 10))\n","            X_uniform_5 = np.random.uniform(-5, 5, (num_auctioneers_per_auction, 10))\n","            X_uniform_2 = np.random.uniform(-2, 2, (num_auctioneers_per_auction, 5))\n","            X_j = np.hstack((X_binary, X_uniform_5, X_uniform_2))\n","\n","            eta_j = np.random.uniform(-5, 5, num_auctioneers_per_auction)#np.random.normal(0, 1, num_auctioneers_per_auction)\n","            mu_j = expit(np.dot(X_j, self.alpha))\n","            bids = self.sample_reparameterized_beta(mu_j, 2, size=num_auctioneers_per_auction)\n","            pCTR_j = self.pCTR_biased.predict_proba(X_j)[:, 1]\n","            auction_scores = bids * pCTR_j\n","            j_star = np.argmax(auction_scores)\n","            p_j = expit(np.dot(X_j[j_star], self.beta) + eta_j[j_star])\n","            y_j = np.zeros(num_auctioneers_per_auction)\n","            y_j[j_star] = bernoulli.rvs(p_j)\n","            D_j = np.zeros(num_auctioneers_per_auction)\n","            D_j[j_star] = 1\n","            historical_data.append((y_j, X_j, bids, D_j))\n","\n","        return historical_data\n","\n","    def flatten_historical_data(self, historical_data):\n","        y_flat = []\n","        X_flat = []\n","        bids_flat = []\n","        D_flat = []\n","\n","        for y_j, X_j, bids, D_j in historical_data:\n","            y_flat.extend(y_j)\n","            X_flat.extend(X_j)\n","            bids_flat.extend(bids)\n","            D_flat.extend(D_j)\n","\n","        y_flat = np.array(y_flat)\n","        X_flat = np.array(X_flat)\n","        bids_flat = np.array(bids_flat)\n","        D_flat = np.array(D_flat)\n","\n","        return y_flat, X_flat, bids_flat, D_flat\n","\n","    def generate_and_train(self, num_records_initial=5000, num_auctions=5000, num_auctioneers_per_auction=20, num_features=25, seed=None):\n","        # Set the seed for this replication\n","        if seed is not None:\n","            np.random.seed(seed)\n","            tf.random.set_seed(seed)\n","        \n","        # Generate parameters\n","        self.generate_parameters(num_features)\n","\n","        # Step 1: Initializing and generating training data\n","        X_k, eta_k, y_k, D_k = self.initialize_training_data(num_records_initial, num_features)\n","\n","        # Define a logistic regression model for pCTR and train it\n","        self.train_logistic_regression(X_k, y_k)\n","\n","        # Step 2: Generating historical auction data\n","        historical_data = self.generate_historical_auction_data(num_auctions, num_auctioneers_per_auction, num_features)\n","\n","        # Flatten the historical data for learning\n","        y_flat, X_flat, bids_flat, D_flat = self.flatten_historical_data(historical_data)\n","\n","        return y_flat, X_flat, bids_flat, D_flat, self.alpha, self.beta, self.gamma\n","\n","# Usage example\n","#auction_data = AuctionData()\n","#y_flat, X_flat, bids_flat, D_flat, alpha, beta, gamma = auction_data.generate_and_train()"]},{"cell_type":"markdown","metadata":{"id":"UMBcSv-xMlWV"},"source":["### Step 3: Define and learn the baselines"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":8728,"status":"ok","timestamp":1718089842521,"user":{"displayName":"R E","userId":"10479407368002365455"},"user_tz":-540},"id":"gY3GSjhcg8Wt"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/emo_157/Desktop/24_coldstart/sim/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n","  warnings.warn(\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","\n","class Naive:\n","    def __init__(self):\n","        self.model = None\n","\n","    def prepare_inputs(self, X, bids):\n","        inputs = {f'X{i+1}': X[:, i].reshape(-1, 1) for i in range(X.shape[1])}\n","        inputs['z'] = bids.reshape(-1, 1)\n","        return inputs\n","\n","    def create_model(self, input_shape):\n","        inputs = {f'X{i+1}': tf.keras.layers.Input(shape=(1,), name=f'X{i+1}') for i in range(input_shape[1])}\n","        inputs_iv = {\"z\": tf.keras.layers.Input(shape=(1,), name=\"z\")}\n","        inputs_with_iv = {**inputs, **inputs_iv}\n","\n","        input_net = tf.keras.layers.Concatenate(axis=-1)(list(inputs.values()))\n","        input_net = tf.keras.layers.BatchNormalization()(input_net)\n","        input_net_iv = tf.keras.layers.Concatenate(axis=-1)([input_net, inputs_iv['z']])\n","\n","        pCTR = tf.keras.layers.Dense(256, activation=\"swish\")(input_net_iv)\n","        pCTR = tf.keras.layers.BatchNormalization()(pCTR)\n","        pCTR = tf.keras.layers.Dense(256, activation=\"relu\")(pCTR)\n","        pCTR = tf.keras.layers.BatchNormalization()(pCTR)\n","        pCTR = tf.keras.layers.Dense(256, activation=\"relu\")(pCTR)\n","        pCTR = tf.keras.layers.BatchNormalization()(pCTR)\n","        pCTR = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"click\")(pCTR)\n","        model = tf.keras.Model(inputs=list(inputs_with_iv.values()), outputs=pCTR)\n","\n","        model.compile(\n","            optimizer=tf.keras.optimizers.Adamax(learning_rate=0.001),\n","            loss=\"binary_crossentropy\",\n","        )\n","        return model\n","\n","    def train_model(self, X_flat, bids_flat, y_flat, D_flat, epochs=40, steps_per_epoch=1000):\n","        inputs_for_nn = self.prepare_inputs(X_flat, bids_flat)\n","        self.model = self.create_model(X_flat.shape)\n","\n","        cp_callback = tf.keras.callbacks.ModelCheckpoint(\n","            filepath=\"checkpoints/naive_checkpoint\",\n","            save_best_only=True,\n","            verbose=1,\n","            monitor=\"loss\",\n","        )\n","        es_callback = tf.keras.callbacks.EarlyStopping(\n","            monitor='loss',\n","            patience=3,\n","            verbose=1\n","        )\n","\n","        self.model.fit(\n","            {**inputs_for_nn},\n","            y_flat,\n","            sample_weight=D_flat,\n","            epochs=epochs,\n","            steps_per_epoch=steps_per_epoch,\n","            callbacks=[cp_callback, es_callback]\n","        )\n","        return self.model\n","\n","# Usage example\n","#naive_instance = Naive()\n","#naive_model = naive_instance.train_model(X_flat, bids_flat, y_flat, D_flat)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1718089842521,"user":{"displayName":"R E","userId":"10479407368002365455"},"user_tz":-540},"id":"ZAT7r2dDmbX6"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","\n","class IVBS:\n","    def __init__(self):\n","        self.model = None\n","\n","    def prepare_inputs(self, X, bids):\n","        inputs = {f'X{i+1}': X[:, i].reshape(-1, 1) for i in range(X.shape[1])}\n","        inputs['z'] = bids.reshape(-1, 1)\n","        return inputs\n","\n","    def create_model(self, input_shape):\n","        inputs = {f'X{i+1}': tf.keras.layers.Input(shape=(1,), name=f'X{i+1}') for i in range(input_shape[1])}\n","        inputs_iv = {\"z\": tf.keras.layers.Input(shape=(1,), name=\"z\")}\n","        inputs_with_iv = {**inputs, **inputs_iv}\n","\n","        inputs_net = tf.keras.layers.Concatenate(axis=-1)(list(inputs.values()))\n","        inputs_iv_net = list(inputs_iv.values())[0]\n","        inputs_net_iv = tf.keras.layers.Concatenate(axis=-1)([inputs_net, inputs_iv_net])\n","\n","        pIMP_iv = tf.keras.layers.Dense(128, activation=\"swish\")(inputs_net_iv)\n","        pIMP_iv = tf.keras.layers.BatchNormalization()(pIMP_iv)\n","        pIMP_iv = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"impression_iv\")(pIMP_iv)\n","        pIMP_iv_model = tf.keras.Model(inputs=inputs_with_iv, outputs=pIMP_iv)\n","\n","        model = tf.keras.Model(inputs=inputs_with_iv, outputs=pIMP_iv_model.output)\n","        model.compile(\n","            optimizer=tf.keras.optimizers.Adamax(learning_rate=0.001),\n","            loss=\"binary_crossentropy\",\n","        )\n","        return model\n","\n","    def train_model(self, X_flat, bids_flat, y_flat, D_flat, epochs=40, steps_per_epoch=1000):\n","        inputs_for_nn = self.prepare_inputs(X_flat, bids_flat)\n","        self.model = self.create_model(X_flat.shape)\n","\n","        cp_callback = tf.keras.callbacks.ModelCheckpoint(\n","            filepath=\"checkpoints/IV-BS_checkpoint\",\n","            save_best_only=True,\n","            verbose=1,\n","            monitor=\"loss\",\n","        )\n","        es_callback = tf.keras.callbacks.EarlyStopping(\n","            monitor='loss',\n","            patience=3,\n","            verbose=1\n","        )\n","\n","        self.model.fit(\n","            {**inputs_for_nn},\n","            y_flat,\n","            sample_weight=D_flat,\n","            epochs=epochs,\n","            steps_per_epoch=steps_per_epoch,\n","            callbacks=[cp_callback, es_callback]\n","        )\n","        return self.model\n","\n","# Usage example\n","#IV-BS_instance = IV-BS()\n","#ivbs_model = ivbs_instance.train_model(X_flat, bids_flat, y_flat, D_flat)"]},{"cell_type":"code","execution_count":4,"metadata":{"collapsed":true,"id":"wLx-479JEYVm"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","\n","class IPS:\n","    def __init__(self):\n","        self.pIMP_model = None\n","        self.pCTR_model = None\n","\n","    def prepare_inputs(self, X, bids):\n","        inputs = {f'X{i+1}': X[:, i].reshape(-1, 1) for i in range(X.shape[1])}\n","        inputs['z'] = bids.reshape(-1, 1)\n","        return inputs\n","\n","    def create_pIMP_model(self, input_shape):\n","        inputs = {f'X{i+1}': tf.keras.layers.Input(shape=(1,), name=f'X{i+1}') for i in range(input_shape[1])}\n","        inputs_iv = {\"z\": tf.keras.layers.Input(shape=(1,), name=\"z\")}\n","        inputs_with_iv = {**inputs, **inputs_iv}\n","\n","        inputs_net = tf.keras.layers.Concatenate(axis=-1)(list(inputs.values()))\n","        inputs_iv_net = list(inputs_iv.values())[0]\n","        inputs_net_iv = tf.keras.layers.Concatenate(axis=-1)([inputs_net, inputs_iv_net])\n","\n","        pIMP_iv = tf.keras.layers.Dense(128, activation=\"swish\")(inputs_net_iv)\n","        pIMP_iv = tf.keras.layers.BatchNormalization()(pIMP_iv)\n","        pIMP_iv = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"impression_iv\")(pIMP_iv)\n","        pIMP_iv_model = tf.keras.Model(inputs=inputs_with_iv, outputs=pIMP_iv)\n","\n","        pIMP_iv_model.compile(\n","            optimizer=tf.keras.optimizers.Adamax(learning_rate=0.001),\n","            loss=\"binary_crossentropy\",\n","        )\n","\n","        return pIMP_iv_model\n","\n","    def train_pIMP_model(self, X_flat, bids_flat, y_flat, epochs=50, steps_per_epoch=1000):\n","        inputs_for_nn = self.prepare_inputs(X_flat, bids_flat)\n","        self.pIMP_model = self.create_pIMP_model(X_flat.shape)\n","\n","        cp_callback = tf.keras.callbacks.ModelCheckpoint(\n","            filepath=\"checkpoints/ipsimp_checkpoint\",\n","            save_best_only=True,\n","            verbose=1,\n","            monitor=\"loss\",\n","        )\n","        es_callback = tf.keras.callbacks.EarlyStopping(\n","            monitor='loss',\n","            patience=3,\n","            verbose=1\n","        )\n","\n","        self.pIMP_model.fit(inputs_for_nn, y_flat, epochs=epochs, steps_per_epoch=steps_per_epoch, callbacks=[cp_callback, es_callback])\n","        return self.pIMP_model\n","\n","    def create_pCTR_model(self, input_shape):\n","        inputs = {f'X{i+1}': tf.keras.layers.Input(shape=(1,), name=f'X{i+1}') for i in range(input_shape[1])}\n","        inputs_net = tf.keras.layers.Concatenate(axis=-1)(list(inputs.values()))\n","\n","        pCTR = tf.keras.layers.Dense(256, activation=\"swish\")(inputs_net)\n","        pCTR = tf.keras.layers.BatchNormalization()(pCTR)\n","        pCTR = tf.keras.layers.Dense(256, activation=\"relu\")(pCTR)\n","        pCTR = tf.keras.layers.BatchNormalization()(pCTR)\n","        pCTR = tf.keras.layers.Dense(256, activation=\"relu\")(pCTR)\n","        pCTR = tf.keras.layers.BatchNormalization()(pCTR)\n","        pCTR = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"click\")(pCTR)\n","        pCTR_model = tf.keras.Model(inputs=inputs, outputs=pCTR)\n","\n","        pCTR_model.compile(\n","            optimizer=tf.keras.optimizers.Adamax(learning_rate=0.001),\n","            loss=\"binary_crossentropy\"\n","        )\n","\n","        return pCTR_model\n","\n","    def train_pCTR_model(self, X_flat, bids_flat, y_flat, epochs=10, steps_per_epoch=1000):\n","        inputs_for_nn = self.prepare_inputs(X_flat, bids_flat)\n","        self.pCTR_model = self.create_pCTR_model(X_flat.shape)\n","\n","        cp_callback = tf.keras.callbacks.ModelCheckpoint(\n","            filepath=\"checkpoints/ipsclk_checkpoint\",\n","            save_best_only=True,\n","            verbose=1,\n","            monitor=\"loss\",\n","        )\n","        es_callback = tf.keras.callbacks.EarlyStopping(\n","            monitor='loss',\n","            patience=3,\n","            verbose=1\n","        )\n","\n","        # Load the pIMP model and predict the impression probabilities\n","        ipsimp = tf.keras.models.load_model(\"checkpoints/ipsimp_checkpoint\")\n","        ips_weight = ipsimp.predict(inputs_for_nn, batch_size=100000, verbose=1).flatten()\n","\n","        # Train the pCTR model with the impression weights\n","        self.pCTR_model.fit(inputs_for_nn, y_flat, sample_weight=ips_weight, epochs=epochs, steps_per_epoch=steps_per_epoch, callbacks=[cp_callback, es_callback])\n","        return self.pCTR_model\n","\n","# Usage example\n","#ips_instance = IPS()\n","#ips_instance.train_pIMP_model(X_flat, bids_flat, y_flat)\n","#ips_model = ips_instance.train_pCTR_model(X_flat, bids_flat, y_flat)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3379,"status":"ok","timestamp":1718110392108,"user":{"displayName":"R E","userId":"10479407368002365455"},"user_tz":-540},"id":"AoJADhIqoP7m"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","\n","class UBIPS:\n","    def __init__(self):\n","        self.model = None\n","\n","    def prepare_inputs(self, X, bids):\n","        inputs = {f'X{i+1}': X[:, i].reshape(-1, 1) for i in range(X.shape[1])}\n","        inputs['z'] = bids.reshape(-1, 1)\n","        return inputs\n","\n","    def create_model(self, input_shape):\n","        inputs = {f'X{i+1}': tf.keras.layers.Input(shape=(1,), name=f'X{i+1}') for i in range(input_shape[1])}\n","        inputs_iv = {\"z\": tf.keras.layers.Input(shape=(1,), name=\"z\")}\n","        inputs_with_iv = {**inputs, **inputs_iv}\n","\n","        input_net = tf.keras.layers.Concatenate(axis=-1)(list(inputs.values()))\n","        input_net = tf.keras.layers.BatchNormalization()(input_net)\n","        input_net_iv = tf.keras.layers.Concatenate(axis=-1)([input_net, inputs_iv['z']])\n","\n","        pIMP_iv = tf.keras.layers.Dense(128, activation=\"swish\")(input_net_iv)\n","        pIMP_iv = tf.keras.layers.BatchNormalization()(pIMP_iv)\n","        pIMP_iv = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"impression_iv\")(pIMP_iv)\n","        pIMP_iv_model = tf.keras.Model(inputs=inputs_with_iv, outputs=pIMP_iv)\n","\n","        pCTR = tf.keras.layers.Dense(256, activation=\"swish\")(input_net)\n","        pCTR = tf.keras.layers.BatchNormalization()(pCTR)\n","        pCTR = tf.keras.layers.Dense(256, activation=\"relu\")(pCTR)\n","        pCTR = tf.keras.layers.BatchNormalization()(pCTR)\n","        pCTR = tf.keras.layers.Dense(256, activation=\"relu\")(pCTR)\n","        pCTR = tf.keras.layers.BatchNormalization()(pCTR)\n","        pCTR = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"click\")(pCTR)\n","        pCTR_model = tf.keras.Model(inputs=inputs_with_iv, outputs=pCTR)\n","\n","        model = tf.keras.Model(\n","            inputs=inputs_with_iv,\n","            outputs=[pCTR_model.output * pIMP_iv_model.output]\n","        )\n","        model.compile(\n","            optimizer=tf.keras.optimizers.Adamax(learning_rate=0.001),\n","            loss=\"binary_crossentropy\",\n","        )\n","\n","        return model\n","\n","    def train_model(self, X_flat, bids_flat, y_flat, D_flat, epochs=50, steps_per_epoch=1000):\n","        inputs_for_nn = self.prepare_inputs(X_flat, bids_flat)\n","        self.model = self.create_model(X_flat.shape)\n","\n","        cp_callback = tf.keras.callbacks.ModelCheckpoint(\n","            filepath=\"checkpoints/ubips_checkpoint\",\n","            save_best_only=True,\n","            verbose=1,\n","            monitor=\"loss\",\n","        )\n","        es_callback = tf.keras.callbacks.EarlyStopping(\n","            monitor='loss',\n","            patience=7,\n","            verbose=1\n","        )\n","\n","        self.model.fit(\n","            {**inputs_for_nn},\n","            [y_flat],\n","            epochs=epochs,\n","            steps_per_epoch=steps_per_epoch,\n","            callbacks=[cp_callback, es_callback]\n","        )\n","        return self.model\n","\n","# Usage example\n","#ubips_instance = UBIPS()\n","#ubips_model = ubips_instance.train_model(X_flat, bids_flat, y_flat, D_flat)"]},{"cell_type":"markdown","metadata":{"id":"bIL7u_ZHYG9S"},"source":["### Step 4: Validating baselines with independently displayed data"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/qb/31p7jmc96_n0fns67992g7x00000gn/T/ipykernel_54931/1861601639.py:132: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n","  plt.boxplot(data[metric], labels=models, patch_artist=True,\n","/var/folders/qb/31p7jmc96_n0fns67992g7x00000gn/T/ipykernel_54931/1861601639.py:132: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n","  plt.boxplot(data[metric], labels=models, patch_artist=True,\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from sklearn.metrics import log_loss, roc_auc_score\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from scipy.special import expit\n","from scipy.stats import bernoulli\n","import os\n","\n","class ModelEvaluation:\n","    def __init__(self, replication_times=20, num_auctions=5000):\n","        self.replication_times = replication_times\n","        self.num_auctions = num_auctions\n","        self.results = {\n","            'Naive': {'LogLoss': [], 'AUC': []},\n","            'IV-BS': {'LogLoss': [], 'AUC': []},\n","            'UBIPS': {'LogLoss': [], 'AUC': []}\n","        }\n","        self.checkpoints_dir = \"bs_checkpoints\"\n","        self.quantile_results = {\n","            'Naive': {'LogLoss': [], 'AUC': []},\n","            'IV-BS': {'LogLoss': [], 'AUC': []},\n","            'UBIPS': {'LogLoss': [], 'AUC': []}\n","        }\n","\n","        os.makedirs(self.checkpoints_dir, exist_ok=True)\n","        os.makedirs(\"res\", exist_ok=True)\n","        os.makedirs(\"figs\", exist_ok=True)\n","\n","    def evaluate_model(self, auction_data):\n","        for iteration in tqdm(range(self.replication_times)):\n","            # Generate training data and train models\n","            y_flat, X_flat, bids_flat, D_flat, alpha, beta, gamma = auction_data.generate_and_train()\n","\n","            naive = Naive()\n","            naive_model = naive.train_model(X_flat, bids_flat, y_flat, D_flat)\n","            naive_model.save(f\"{self.checkpoints_dir}/naive_model_{iteration}.h5\")\n","\n","            ivbs = IVBS()\n","            ivbs_model = ivbs.train_model(X_flat, bids_flat, y_flat, D_flat)\n","            ivbs_model.save(f\"{self.checkpoints_dir}/ivbs_model_{iteration}.h5\")\n","\n","            ubips = UBIPS()\n","            ubips_model = ubips.train_model(X_flat, bids_flat, y_flat, D_flat)\n","            ubips_model.save(f\"{self.checkpoints_dir}/ubips_model_{iteration}.h5\")\n","\n","            # Generate validation data\n","            num_records_validation = 50000\n","            X_binary = np.random.binomial(1, 0.5, (num_records_validation, 10))\n","            X_uniform_5 = np.random.uniform(-5, 5, (num_records_validation, 10))\n","            X_uniform_2 = np.random.uniform(-2, 2, (num_records_validation, 5))\n","            X_l = np.hstack((X_binary, X_uniform_5, X_uniform_2))\n","            eta_l = np.random.uniform(-5, 5, num_records_validation)\n","            mu_l = expit(np.dot(X_l, alpha))\n","            bids = auction_data.sample_reparameterized_beta(mu_l, 2, size=num_records_validation)\n","            p_l = expit(np.dot(X_l, beta) + eta_l)\n","            y_l = bernoulli.rvs(p_l)\n","            inputs_for_validation = naive.prepare_inputs(X_l, bids)\n","\n","            # Save validation data\n","            np.savez(f\"{self.checkpoints_dir}/validation_data_{iteration}.npz\", X_l=X_l, bids=bids, y_l=y_l)\n","\n","            # Load the models\n","            naive = tf.keras.models.load_model(f\"{self.checkpoints_dir}/naive_model_{iteration}.h5\")\n","            ivbs = tf.keras.models.load_model(f\"{self.checkpoints_dir}/ivbs_model_{iteration}.h5\")\n","            ubips = tf.keras.models.load_model(f\"{self.checkpoints_dir}/ubips_model_{iteration}.h5\")\n","\n","            # Naive model prediction\n","            naive_predictions = naive.predict(inputs_for_validation).flatten()\n","            naive_logloss = log_loss(y_l, naive_predictions)\n","            naive_auc = roc_auc_score(y_l, naive_predictions)\n","\n","            # IV-BS model prediction\n","            ivbs_predictions = ivbs.predict(inputs_for_validation)\n","            if isinstance(ivbs_predictions, list):\n","                ivbs_predictions = ivbs_predictions[0].flatten()\n","            else:\n","                ivbs_predictions = ivbs_predictions.flatten()\n","            ivbs_logloss = log_loss(y_l, ivbs_predictions)\n","            ivbs_auc = roc_auc_score(y_l, ivbs_predictions)\n","\n","            # UBIPS model prediction\n","            ubips_predictions = ubips.predict(inputs_for_validation)\n","            if isinstance(ubips_predictions, list):\n","                ubips_predictions = ubips_predictions[0].flatten()\n","            else:\n","                ubips_predictions = ubips_predictions.flatten()\n","            ubips_logloss = log_loss(y_l, ubips_predictions)\n","            ubips_auc = roc_auc_score(y_l, ubips_predictions)\n","\n","            # Store results\n","            self.results['Naive']['LogLoss'].append(naive_logloss)\n","            self.results['Naive']['AUC'].append(naive_auc)\n","\n","            self.results['IV-BS']['LogLoss'].append(ivbs_logloss)\n","            self.results['IV-BS']['AUC'].append(ivbs_auc)\n","\n","            self.results['UBIPS']['LogLoss'].append(ubips_logloss)\n","            self.results['UBIPS']['AUC'].append(ubips_auc)\n","\n","            # Quantile validation\n","            filtered_dfs = self.create_filtered_dfs(X_l, bids, eta_l, y_l)\n","            quantile_results = self.evaluate_quantiles(filtered_dfs, naive, ivbs, ubips)\n","\n","            for model in self.results.keys():\n","                for metric in ['LogLoss', 'AUC']:\n","                    self.quantile_results[model][metric].extend(quantile_results[model][metric])\n","\n","            self.save_results()\n","\n","    def save_results(self):\n","        np.save(\"res/results.npy\", self.results)\n","        np.save(\"res/quantile_results.npy\", self.quantile_results)\n","\n","    def load_results(self):\n","        self.results = np.load(\"res/results.npy\", allow_pickle=True).item()\n","        self.quantile_results = np.load(\"res/quantile_results.npy\", allow_pickle=True).item()\n","\n","    def plot_results(self):\n","        models = ['Naive', 'IV-BS', 'UBIPS']\n","        metrics = ['AUC', 'LogLoss']\n","        colors = ['#1f77b4', '#ff7f0e', '#8c564b']\n","\n","        data = {metric: [] for metric in metrics}\n","        for metric in metrics:\n","            for model in models:\n","                data[metric].append(self.results[model][metric])\n","\n","        plt.figure(figsize=(15, 10))\n","        for i, metric in enumerate(metrics):\n","            plt.subplot(1, 2, i + 1)\n","            plt.boxplot(data[metric], labels=models, patch_artist=True,\n","                        boxprops=dict(facecolor=colors[i], color=colors[i]),\n","                        medianprops=dict(color='black'),\n","                        whiskerprops=dict(color=colors[i]),\n","                        capprops=dict(color=colors[i]),\n","                        flierprops=dict(markerfacecolor=colors[i], markeredgecolor=colors[i]))\n","            plt.title(metric)\n","            plt.xlabel('Model')\n","            #plt.ylabel(metric)\n","        plt.savefig(\"figs/results_boxplot.pdf\")\n","        plt.close()\n","\n","    def evaluate_saved_models(self):\n","        models = ['Naive', 'IV-BS', 'UBIPS']\n","        for iteration in range(self.replication_times):\n","            # Load validation data\n","            data = np.load(f\"{self.checkpoints_dir}/validation_data_{iteration}.npz\")\n","            X_l = data['X_l']\n","            bids = data['bids']\n","            y_l = data['y_l']\n","            inputs_for_validation = Naive().prepare_inputs(X_l, bids)\n","\n","            results = {model: {'LogLoss': None, 'AUC': None} for model in models}\n","            for model_name in models:\n","                model = tf.keras.models.load_model(f\"{self.checkpoints_dir}/{model_name.lower()}_model_{iteration}.h5\")\n","                predictions = model.predict(inputs_for_validation).flatten()\n","                LogLoss = log_loss(y_l, predictions)\n","                AUC = roc_auc_score(y_l, predictions)\n","\n","                results[model_name]['LogLoss'] = LogLoss\n","                results[model_name]['AUC'] = AUC\n","\n","                self.results[model_name]['LogLoss'].append(LogLoss)\n","                self.results[model_name]['AUC'].append(AUC)\n","\n","            self.save_results()\n","\n","    def plot_intermediate_results(self):\n","        try:\n","            self.load_results()\n","        except:\n","            pass\n","\n","        self.plot_results()\n","        self.plot_quantile_results()\n","\n","    # Functions for quantile validation\n","    def create_filtered_dfs(self, X_l, bids, eta_l, y_l):\n","        filtered_dfs = {}\n","        for lower_quantile in range(5, 51, 5):\n","            upper_quantile = 100 - lower_quantile\n","\n","            lower_bound = np.percentile(eta_l, lower_quantile)\n","            upper_bound = np.percentile(eta_l, upper_quantile)\n","\n","            relevant_indices = np.where((eta_l <= lower_bound) | (eta_l >= upper_bound))[0]\n","\n","            filtered_dfs[f\"{lower_quantile * 2}\"] = {\n","                'X': X_l[relevant_indices],\n","                'bids': bids[relevant_indices],\n","                'y': y_l[relevant_indices]\n","            }\n","\n","        return filtered_dfs\n","\n","    def evaluate_quantiles(self, filtered_dfs, naive, ivbs, ubips):\n","        results = {\n","            'Naive': {'LogLoss': [], 'AUC': []},\n","            'IV-BS': {'LogLoss': [], 'AUC': []},\n","            'UBIPS': {'LogLoss': [], 'AUC': []}\n","        }\n","\n","        for key, data in filtered_dfs.items():\n","            X_filtered = data['X']\n","            bids_filtered = data['bids']\n","            y_filtered = data['y']\n","\n","            # Evaluate Naive model\n","            naive_logloss, naive_auc = self.evaluate_model_on_quantile(X_filtered, bids_filtered, y_filtered, naive)\n","            results['Naive']['LogLoss'].append(naive_logloss)\n","            results['Naive']['AUC'].append(naive_auc)\n","\n","            # Evaluate IVBS model\n","            ivbs_logloss, ivbs_auc = self.evaluate_model_on_quantile(X_filtered, bids_filtered, y_filtered, ivbs)\n","            results['IV-BS']['LogLoss'].append(ivbs_logloss)\n","            results['IV-BS']['AUC'].append(ivbs_auc)\n","\n","            # Evaluate UBIPS model\n","            ubips_logloss, ubips_auc = self.evaluate_model_on_quantile(X_filtered, bids_filtered, y_filtered, ubips)\n","            results['UBIPS']['LogLoss'].append(ubips_logloss)\n","            results['UBIPS']['AUC'].append(ubips_auc)\n","\n","        return results\n","\n","    def evaluate_model_on_quantile(self, X_filtered, bids_filtered, y_filtered, model):\n","        inputs_for_eval = Naive().prepare_inputs(X_filtered, bids_filtered)\n","        predictions = model.predict(inputs_for_eval)\n","        if isinstance(predictions, list):\n","            predictions = predictions[0].flatten()\n","        else:\n","            predictions = predictions.flatten()\n","\n","        LogLoss = log_loss(y_filtered, predictions)\n","        AUC = roc_auc_score(y_filtered, predictions)\n","\n","        return LogLoss, AUC\n","\n","    def plot_quantile_results(self):\n","        metrics = [\"AUC\", \"LogLoss\"]\n","        model_order = ['Naive', 'IV-BS', 'UBIPS']\n","        colors = {\n","            'Naive': '#1f77b4',\n","            'IV-BS': '#ff7f0e',\n","            'UBIPS': '#8c564b',\n","        }\n","\n","        quantiles = sorted(list(self.create_filtered_dfs(np.zeros((10, 10)), np.zeros(10), np.zeros(10), np.zeros(10)).keys()), key=lambda x: int(x))\n","\n","        for metric in metrics:\n","            fig, ax1 = plt.subplots(figsize=(18, 10))\n","            positions = np.arange(len(quantiles))\n","\n","            # Boxplot for each model\n","            for model, color in zip(model_order, colors.values()):\n","                data = [self.quantile_results[model][metric][i::len(quantiles)] for i in range(len(quantiles))]\n","                bp = ax1.boxplot(\n","                    data,\n","                    positions=positions,\n","                    widths=0.6,\n","                    patch_artist=True,\n","                    boxprops=dict(facecolor=color, color=color),\n","                    medianprops=dict(color='black'),\n","                    whiskerprops=dict(color=color),\n","                    capprops=dict(color=color),\n","                    flierprops=dict(markerfacecolor=color, markeredgecolor=color)\n","                )\n","                for box in bp['boxes']:\n","                    box.set_label(model)\n","\n","            ax1.set_xlabel(\"Outside Quantiles of $\\eta_l$ in Users' Click Response\", fontsize=20)\n","            ax1.set_ylabel(metric, fontsize=20)\n","            ax1.set_xticks(positions)\n","            ax1.set_xticklabels(quantiles, fontsize=20)\n","            ax1.tick_params(axis='y', labelsize=20)\n","\n","            # Calculate relative improvement\n","            if metric == \"AUC\":\n","                baseline = np.array([self.quantile_results['Naive'][metric][i::len(quantiles)] for i in range(len(quantiles))])\n","                improvements = {model: [] for model in model_order if model != 'Naive'}\n","                for model in improvements.keys():\n","                    model_data = np.array([self.quantile_results[model][metric][i::len(quantiles)] for i in range(len(quantiles))])\n","                    relative_improvement = ((model_data - 0.5) / (baseline - 0.5) - 1) * 100\n","                    improvements[model] = relative_improvement\n","            elif metric == \"LogLoss\":\n","                baseline = np.array([self.quantile_results['Naive'][metric][i::len(quantiles)] for i in range(len(quantiles))])\n","                improvements = {model: [] for model in model_order if model != 'Naive'}\n","                for model in improvements.keys():\n","                    model_data = np.array([self.quantile_results[model][metric][i::len(quantiles)] for i in range(len(quantiles))])\n","                    relative_improvement = (baseline - model_data) / baseline * 100\n","                    improvements[model] = relative_improvement\n","\n","            # Plot relative improvement\n","            ax2 = ax1.twinx()\n","            for model, color in zip([m for m in model_order if m != 'Naive'], [colors[m] for m in model_order if m != 'Naive']):\n","                mean_improvement = np.mean(improvements[model], axis=1)\n","                std_improvement = np.std(improvements[model], axis=1)\n","                ax2.plot(positions, mean_improvement, color=color, marker='o', label=f'Relative {model}')\n","                ax2.fill_between(positions, mean_improvement - std_improvement, mean_improvement + std_improvement, color=color, alpha=0.2)\n","            \n","            # Add Naive model's relative improvement (always 0%)\n","            ax2.axhline(0, color=colors['Naive'], linestyle='--', label='Relative Naive')\n","\n","            ax2.set_ylabel(f'Relative {metric} Improvement (%)', fontsize=20)\n","            ax2.tick_params(axis='y', labelsize=20)\n","            \n","            legend_elements = [plt.Line2D([0], [0], color=color, lw=4, label=model) for model, color in colors.items()]\n","            ax1.legend(handles=legend_elements, loc='best', fontsize=14)\n","\n","            plt.tight_layout()\n","            plt.savefig(f\"figs/sim_{metric}.pdf\", bbox_inches='tight')\n","            plt.close()\n","\n","# Usage example\n","evaluation = ModelEvaluation(replication_times=20)\n","#evaluation.evaluate_model(AuctionData())\n","#evaluation.plot_results()\n","#evaluation.plot_quantile_results()\n","evaluation.plot_intermediate_results()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":["O6QtWpncljUY"],"provenance":[]},"kernelspec":{"display_name":"Python (venv)","language":"python","name":"venv"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"vscode":{"interpreter":{"hash":"5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"}}},"nbformat":4,"nbformat_minor":0}
